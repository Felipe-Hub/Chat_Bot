{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1014351117149352633\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 14591099164818806848\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5399445504\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 8841533958096816652\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13066002113158655287\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python import keras\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "from tensorflow.python.keras import backend\n",
    "backend.set_session(session)\n",
    "print(backend._get_available_gpus())\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package brown to /home/felipe/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "potions: re, numpy as np, pandas as pd, pickle, json, nltk, keras, collections\n",
      "spells: clean_data, clean_entire, predict_tags, tagged_3D, tagged_n_grams, unknown_words_X, check_and_predict\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.models import Input, Model, load_model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense, LSTM, Concatenate, Embedding, Bidirectional\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from random import randint, choice\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../utils')\n",
    "from NLP_little_helpers import *\n",
    "little_helpers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../utils')\n",
    "\n",
    "from data_cleaning import clean_entire\n",
    "from pos_tagging import predict_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.gutenberg.org/browse/scores/top'\n",
    "response_url = requests.get(url, headers={'user-agent': 'Mozilla/5.0'})\n",
    "soup = BeautifulSoup(response_url.content, 'lxml')\n",
    "\n",
    "book_id = [i.find('a').get('href').replace('/ebooks/', '') for i in soup.find_all('li') if i.find('a').get('href').startswith('/ebooks/')]\n",
    "urls = ['http://www.gutenberg.org/cache/epub/'+i+'/pg'+i+'.txt' for i in book_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = list()\n",
    "\n",
    "for url in urls:\n",
    "    response_url = requests.get(url, headers={'user-agent': 'Mozilla/5.0'})\n",
    "    soup = BeautifulSoup(response_url.content, 'lxml')\n",
    "    books += [soup.find('p').get_text(' ', strip=True)]\n",
    "    \n",
    "print(len(books), 'books scraped.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('books_and_datasets/100_books.txt', 'wb') as file:\n",
    "#    pickle.dump(books, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('books_and_datasets/100_books.txt', 'rb') as file:\n",
    "    books = pickle.load(file)[:100]\n",
    "\n",
    "books[53] = ''\n",
    "books[16] = ''\n",
    "books[58] = ''\n",
    "books[18] = ''\n",
    "books[37] = ''\n",
    "books[50] = ''\n",
    "books[6] = ''\n",
    "books[68] = ''\n",
    "books[70] = ''\n",
    "books[71] = ''\n",
    "books[73] = ''\n",
    "books[57] = ''\n",
    "books[76] = ''\n",
    "books[83] = ''\n",
    "books[84] = ''\n",
    "books[85] = ''\n",
    "books[86] = ''\n",
    "books[87] = ''\n",
    "books[88] = ''\n",
    "books[89] = ''\n",
    "books[90] = ''\n",
    "books[91] = ''\n",
    "books[94] = ''\n",
    "books[96] = ''\n",
    "books[99] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = list(set(clean_entire(' '.join(books))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'but since hammerpurgstall and de sacy began to unwind the skein , many additional turns have been given',\n",
       " 'thus , when herschel was prosecuting his beautiful observations on the other side of the channel , we had not even the means of verifying them',\n",
       " 'as soon as the first brood had flown , and while they were yet under their parents care , they began to nest in one of the other boxes , the female as usual doing all the work and the male all the complimenting',\n",
       " 'a young man , a farmlabourer , as come by us on his way to market with his masrs draysa journey of over five hundred mile , theer and backmade offers fur to take her fur his wife wives is very scarce theer , and then to set up fur their two selves in the bush']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(clean_text))\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Trained_Weights/hmm_model.pkl', 'rb') as file:\n",
    "    hmm_model = pickle.load(file)\n",
    "    \n",
    "viterbis_dict = [predict_tags(text, hmm_model) for text in clean_text if len(text) > 20]\n",
    "\n",
    "with open('../Data/100_books_tagged.json', 'w') as outfile:\n",
    "    json.dump(viterbis_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
